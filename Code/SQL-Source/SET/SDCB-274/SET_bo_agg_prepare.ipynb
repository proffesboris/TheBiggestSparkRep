{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context is ready 2018-04-26T14:19:34.189465\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "spark_home = '/opt/cloudera/parcels/SPARK2_INCLUDE_SPARKR/lib/spark2'\n",
    "os.environ['SPARK_HOME'] = spark_home\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'python'\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/cloudera/parcels/PYENV.ZNO20008661/bin/python'\n",
    "sys.path.insert(0, os.path.join (spark_home,'python'))\n",
    "sys.path.insert(0, os.path.join (spark_home,'python/lib/py4j-0.10.4-src.zip'))\n",
    "from pyspark import SparkContext, SparkConf, HiveContext\n",
    "\n",
    "N_INSTANCES = 100\n",
    "N_CORES = 1\n",
    "PARALLELISM = N_INSTANCES*N_CORES*10\n",
    "conf = SparkConf().setAppName('Prep-SET').setMaster(\"yarn-client\")\n",
    "conf.setAll(\n",
    "    [\n",
    "        ('spark.driver.memory','20g'),\n",
    "        ('spark.executor.memory','8g'),\n",
    "        ('spark.driver.maxResultSize','5g'),\n",
    "        ('spark.port.maxRetries', '150'),\n",
    "        ('spark.executor.cores', N_CORES),\n",
    "        ('spark.executor.instances',N_INSTANCES),\n",
    "        ('spark.default.parallelism',PARALLELISM),\n",
    "        ('spark.sql.shuffle.partitions',PARALLELISM),\n",
    "        ('spark.yarn.executor.memoryOverhead','20g'),\n",
    "        ('spark.dynamicAllocation.enabled', 'false'),\n",
    "        ('spark.dynamicAllocation.enabled', 'false')\n",
    "        #('spark.kryoserializer.buffer.max','1g'),\n",
    "        #('spark.dynamicAllocation.minExecutors',50),\n",
    "        #('spark.dynamicAllocation.maxExecutors',100),\n",
    "    ]\n",
    ")\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sqlc=HiveContext(sc)\n",
    "sqlContext=HiveContext(sc)\n",
    "print('Context is ready {DTTM}'.format(DTTM = datetime.datetime.fromtimestamp(time.time()).isoformat()))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libs ready 2018-04-26T14:20:09.366170\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cm import inferno\n",
    "from matplotlib.backends import backend_pdf\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from gc import collect\n",
    "%matplotlib inline\n",
    "print('libs ready {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:12:09.706741\n"
     ]
    }
   ],
   "source": [
    "#Згрузим данные из HDFS в Pandas\n",
    "paym =  sqlContext.sql('select * from t_team_k7m_aux_p.set_paym')\n",
    "tr=paym.toPandas()\n",
    "wro =  sqlContext.sql('select * from t_team_k7m_aux_p.set_wro')\n",
    "wo=wro.toPandas()\n",
    "tc4 =  sqlContext.sql('select * from t_team_k7m_aux_p.set_cred_enriched')\n",
    "deals=tc4.toPandas()\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:12:10.709666\n"
     ]
    }
   ],
   "source": [
    "#переведем даты в даты\n",
    "tr['c_date_notunix'] = pd.to_datetime(tr['c_date'])\n",
    "tr = tr.sort_values('c_date_notunix')\n",
    "tr = tr.reset_index(drop = True)\n",
    "\n",
    "deals['c_date_ending'] = pd.to_datetime(deals['c_date_ending'])\n",
    "deals['ddog'] = pd.to_datetime(deals['ddog'])\n",
    "deals['date_close'] = pd.to_datetime(deals['date_close'])\n",
    "\n",
    "\n",
    "wo['c_date_notunix'] = pd.to_datetime(wo['c_date'])\n",
    "wo = wo.sort_values('c_date_notunix')\n",
    "wo = wo.reset_index(drop = True)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:12:16.357069\n"
     ]
    }
   ],
   "source": [
    "#на всякий пожарный оставим в транзакциях только транзакции которые относятся к нашим договорам\n",
    "tr = tr[ tr['pr_cred_id'].isin(deals['pr_cred_id'].unique()) ].reset_index(drop = True)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:12:16.670384\n"
     ]
    }
   ],
   "source": [
    "#создадис датасет = ответ\n",
    "agg=deals.copy().reset_index()\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:12:54.879599\n"
     ]
    }
   ],
   "source": [
    "#сагрегируем данные о транзакциях гашения\n",
    "trs = tr.groupby('pr_cred_id')['c_summa'].sum().reset_index()\n",
    "trs['c_summa_in_cr_v'] = tr.groupby(['pr_cred_id'])['c_summa_in_cr_v'].sum().values\n",
    "trs['start_date'] = tr.groupby(['pr_cred_id'])['c_date_notunix'].min().values\n",
    "trs['end_date'] = tr.groupby(['pr_cred_id'])['c_date_notunix'].max().values\n",
    "trs['count'] = tr.groupby(['pr_cred_id']).size().values\n",
    "agg = agg.merge(trs, on = 'pr_cred_id', how='left')\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:12:55.107875\n"
     ]
    }
   ],
   "source": [
    "#сагрегируем данные о транзакциях списания\n",
    "trs_wo = wo.groupby('pr_cred_id')['c_summa'].sum().reset_index()[['pr_cred_id','c_summa']]\n",
    "trs_wo['c_summa_in_cr_v'] = wo.groupby(['pr_cred_id'])['c_summa_in_cr_v'].sum().values\n",
    "trs_wo.rename(columns={'c_summa':'wo_summa', 'c_summa_in_cr_v':'wo_summa_in_cr_v'}, inplace=True)\n",
    "agg = agg.merge(trs_wo, on = 'pr_cred_id', how='left')\n",
    "agg['wo_summa'].fillna(0,inplace=True)\n",
    "agg['wo_summa_in_cr_v'].fillna(0,inplace=True)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:13:34.892329\n"
     ]
    }
   ],
   "source": [
    "#продолжим формировать агрегаты. сумма по транзакциям, накопленную сумму по транзакциям, когда мы прошли 5%, 10%, 15% уровень.\n",
    "tr['total'] = tr.groupby('pr_cred_id')['c_summa'].transform('sum')\n",
    "tr['total_in_cr_v'] = tr.groupby('pr_cred_id')['c_summa_in_cr_v'].transform('sum')\n",
    "tr['c_summa'] = pd.to_numeric(tr['c_summa'])\n",
    "tr['cumsum'] = tr.groupby('pr_cred_id')['c_summa'].cumsum()\n",
    "tr['c_summa_in_cr_v'] = pd.to_numeric(tr['c_summa_in_cr_v'])\n",
    "tr['cumsum_in_cr_v'] = tr.groupby('pr_cred_id')['c_summa_in_cr_v'].cumsum()\n",
    "tr['total_in_cr_v'] = pd.to_numeric(tr['total_in_cr_v'])\n",
    "tr['alpha_005'] = (tr['cumsum_in_cr_v']>tr['total_in_cr_v']*float(0.05))\n",
    "tr['alpha_01'] = (tr['cumsum_in_cr_v']>tr['total_in_cr_v']*0.1)\n",
    "tr['alpha_015'] = (tr['cumsum_in_cr_v']>tr['total_in_cr_v']*0.15)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/cloudera/parcels/PYENV.ZNO20008661/lib/python3.5/site-packages/ipykernel/__main__.py:11: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:14:05.371028\n"
     ]
    }
   ],
   "source": [
    "#для  5%, 10%, 15% уровеня подсчитаем сумму до и дату\n",
    "argmax_custom = lambda x : x.argmax()\n",
    "\n",
    "trs2 = tr.groupby('pr_cred_id')['alpha_005'].apply( argmax_custom ).reset_index()\n",
    "trs2.rename(columns={'alpha_005':'alpha_005_id'}, inplace=True)\n",
    "\n",
    "trs2['alpha_01_id'] = tr.groupby('pr_cred_id')['alpha_01'].apply( argmax_custom ).values\n",
    "trs2['alpha_015_id'] = tr.groupby('pr_cred_id')['alpha_015'].apply( argmax_custom ).values\n",
    "trs2['total']=tr.groupby('pr_cred_id')['c_summa_in_cr_v'].sum().values\n",
    "\n",
    "trs2['alpha_005_cumsum'] = tr.ix[trs2['alpha_005_id'], 'cumsum_in_cr_v'].values\n",
    "trs2['alpha_01_cumsum'] = tr.ix[trs2['alpha_01_id'], 'cumsum_in_cr_v'].values\n",
    "trs2['alpha_015_cumsum'] = tr.ix[trs2['alpha_015_id'], 'cumsum_in_cr_v'].values\n",
    "\n",
    "trs2['alpha_005_date'] = tr.ix[trs2['alpha_005_id'], 'c_date_notunix'].values\n",
    "trs2['alpha_01_date'] = tr.ix[trs2['alpha_01_id'], 'c_date_notunix'].values\n",
    "trs2['alpha_015_date'] = tr.ix[trs2['alpha_015_id'], 'c_date_notunix'].values\n",
    "\n",
    "agg = agg.merge(trs2, on = 'pr_cred_id', how='left')\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:24.284325\n"
     ]
    }
   ],
   "source": [
    "#определим баллон, и его дату\n",
    "tr3 = tr.groupby('pr_cred_id')['c_date_notunix'].last().reset_index()\n",
    "tr3.rename(columns={'c_date_notunix':'balon_date'}, inplace=True)\n",
    "agg = agg.merge(tr3, on = 'pr_cred_id', how='left')\n",
    "\n",
    "agg['balon_date']=agg['c_date_ending'].where(agg['balon_date'].isnull(),other = agg['balon_date'])\n",
    "\n",
    "agg['days_after_balon'] = (agg['balon_date'] - agg['ddog']).apply( lambda x :\\\n",
    "                                                 relativedelta(days = int(x.days*0.9)).days)\n",
    "agg['date_balon_starts'] = (agg['balon_date'] - agg['ddog']).apply( lambda x :\\\n",
    "                                                 relativedelta(days = int(x.days*0.9)))\n",
    "agg['days_balon_starts'] = agg.apply( lambda x : x['ddog'] + x['date_balon_starts'], axis = 1)\n",
    "\n",
    "tr = tr.merge(agg[['pr_cred_id', 'days_balon_starts'] ], on = 'pr_cred_id', how='left')\n",
    "\n",
    "sum_balon = lambda x : x['c_summa_in_cr_v']*(x['c_date_notunix']>=x['days_balon_starts'])\n",
    "tr['isin_balon'] = tr['c_date_notunix']>=tr['days_balon_starts']\n",
    "tr['balon_part'] = tr.apply( lambda x : sum_balon(x), axis = 1)\n",
    "\n",
    "tr4 = tr.groupby('pr_cred_id')['balon_part'].sum().reset_index()\n",
    "tr4.rename(columns={'balon_part':'balon_sum'}, inplace=True)\n",
    "agg = agg.merge(tr4, on = 'pr_cred_id', how='left')\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:25.264318\n"
     ]
    }
   ],
   "source": [
    "#переведем даты в дистанции от ddog\n",
    "agg['days_over_lim'] = (agg['c_date_ending'] - agg['end_date']).apply( lambda x : x.days)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:26.276878\n"
     ]
    }
   ],
   "source": [
    "agg['start_date'] = agg['start_date'] - agg['ddog']\n",
    "agg['end_date']  = (agg['end_date'] - agg['ddog']).apply( lambda x : x.days)\n",
    "agg['avp_in_days'].fillna(0,inplace=True)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:26.303266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agg['alpha_005_date'] = (agg['alpha_005_date'] - agg['ddog'])# - agg['avp_in_days'].apply(lambda x: timedelta(days = x))\n",
    "agg['alpha_01_date'] = (agg['alpha_01_date'] - agg['ddog'] )#- agg['avp_in_days'].apply(lambda x: timedelta(days = x ))\n",
    "agg['alpha_015_date'] = agg['alpha_015_date'] - agg['ddog']#- agg['avp_in_days'].apply(lambda x: timedelta(days = x))\n",
    "agg['balon_date'] = agg['balon_date'] - agg['ddog']\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:48.251393\n"
     ]
    }
   ],
   "source": [
    "#определим параметры гаммы\n",
    "tr['graph_y'] = 1-(tr['cumsum_in_cr_v']-tr['c_summa_in_cr_v'])/tr['total_in_cr_v']\n",
    "tr = tr.merge(deals[['pr_cred_id', 'ddog', 'dur_in_days']], on = 'pr_cred_id')\n",
    "tr['graph_x'] = (tr['c_date_notunix'] - tr['ddog']).apply( lambda x : x.days)/tr['dur_in_days']\n",
    "tr['ro'] = np.sqrt( (1-tr['graph_y'])**2 + (1-tr['graph_x'])**2 )\n",
    " \n",
    "agg = agg.merge(tr[tr['ro'] == tr.groupby('pr_cred_id')['ro'].transform('min')\\\n",
    "            ][['pr_cred_id', 'graph_x', 'graph_y']], on = 'pr_cred_id', how='left')\n",
    "agg['bias'] = agg['graph_x'] + agg['graph_y']\n",
    "agg['gamma']= -1 + agg['bias']\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:48.296815\n"
     ]
    }
   ],
   "source": [
    "#переведем суммы во флоат\n",
    "agg['summa_ru'] = agg['summa_ru'].astype('float')\n",
    "agg['summa_base'] = agg['summa_base'].astype('float')\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:48.322482\n"
     ]
    }
   ],
   "source": [
    "#определим накопленные суммы в долях от суммы\n",
    "agg['alpha_005_cumsum_t'] = agg['alpha_005_cumsum']/agg['total']\n",
    "agg['alpha_01_cumsum_t'] = agg['alpha_01_cumsum']/agg['total']\n",
    "agg['alpha_015_cumsum_t'] = agg['alpha_015_cumsum']/agg['total']\n",
    "agg['balon_sum_t'] = agg['balon_sum']/agg['total']\n",
    "\n",
    "agg['alpha_005_cumsum_d'] = agg['alpha_005_cumsum']/agg['summa_base']\n",
    "agg['alpha_01_cumsum_d'] = agg['alpha_01_cumsum']/agg['summa_base']\n",
    "agg['alpha_015_cumsum_d'] = agg['alpha_015_cumsum']/agg['summa_base']\n",
    "agg['balon_sum_d'] = agg['balon_sum']/agg['summa_base']\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:49.405559\n",
      "step 2018-04-26T16:18:51.010931\n",
      "step 2018-04-26T16:18:52.564736\n",
      "step 2018-04-26T16:18:54.237262\n",
      "step 2018-04-26T16:18:55.348287\n"
     ]
    }
   ],
   "source": [
    "#а сроки в полях от дюрации\n",
    "for c in ['start_date', 'alpha_005_date', 'alpha_01_date', 'alpha_015_date', 'balon_date']:\n",
    "    agg[c] = agg[c].apply( lambda x : x.days)/(agg['dur_in_days']) \n",
    "    print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:18:55.870470\n"
     ]
    }
   ],
   "source": [
    "#сохранение\n",
    "agg2=agg.copy()\n",
    "agg2=agg2.drop('date_balon_starts',axis=1)\n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2018-04-26T16:35:15.912189\n"
     ]
    }
   ],
   "source": [
    "#сохраняем результат в файл\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "mySchema = StructType([\\\n",
    "  StructField(\"index\", IntegerType(), True)\\\n",
    " ,StructField(\"client_id\", StringType(), True)\\\n",
    " ,StructField(\"client_name\", StringType(), True)\\\n",
    " ,StructField(\"inn\", StringType(), True)\\\n",
    " ,StructField(\"kpp\", StringType(), True)\\\n",
    " ,StructField(\"crm_segment\", StringType(), True)\\\n",
    " ,StructField(\"ndog\", StringType(), True)\\\n",
    " ,StructField(\"ddog\", StringType(), True)\\\n",
    " ,StructField(\"dur_in_days\", IntegerType(), True)\\\n",
    " ,StructField(\"dur_in_month\", DoubleType(), True)\\\n",
    " ,StructField(\"c_date_ending\", StringType(), True)\\\n",
    " ,StructField(\"date_close\", StringType(), True)\\\n",
    " ,StructField(\"summa_base\", DoubleType(), True)\\\n",
    " ,StructField(\"summa_ru\", DoubleType(), True)\\\n",
    " ,StructField(\"c_ft_credit\", StringType(), True)\\\n",
    " ,StructField(\"limit_amt\", StringType(), True)\\\n",
    " ,StructField(\"regime_prod\", StringType(), True)\\\n",
    " ,StructField(\"cred_flag\", IntegerType(), True)\\\n",
    " ,StructField(\"over_flag\", IntegerType(), True)\\\n",
    " ,StructField(\"instrument\", StringType(), True)\\\n",
    " ,StructField(\"avp_in_days\", DoubleType(), True)\\\n",
    " ,StructField(\"avp_in_month\", DoubleType(), True)\\\n",
    " ,StructField(\"target_cred\", StringType(), True)\\\n",
    " ,StructField(\"product_status\", StringType(), True)\\\n",
    " ,StructField(\"c_list_pay\", StringType(), True)\\\n",
    " ,StructField(\"pr_cred_id\", StringType(), True)\\\n",
    " ,StructField(\"branch\", StringType(), True)\\\n",
    " ,StructField(\"branch_ru\", StringType(), True)\\\n",
    " ,StructField(\"int_revenue\", StringType(), True)\\\n",
    " ,StructField(\"fok_revenue\", StringType(), True)\\\n",
    " ,StructField(\"report_month_ago\", DoubleType(), True)\\\n",
    " ,StructField(\"c_summa\", StringType(), True)\\\n",
    " ,StructField(\"c_summa_in_cr_v\", StringType(), True)\\\n",
    " ,StructField(\"start_date\", DoubleType(), True)\\\n",
    " ,StructField(\"end_date\", DoubleType(), True)\\\n",
    " ,StructField(\"count\", DoubleType(), True)\\\n",
    " ,StructField(\"wo_summa\", StringType(), True)\\\n",
    " ,StructField(\"wo_summa_in_cr_v\", StringType(), True)\\\n",
    " ,StructField(\"alpha_005_id\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_01_id\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_015_id\", DoubleType(), True)\\\n",
    " ,StructField(\"total\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_005_cumsum\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_01_cumsum\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_015_cumsum\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_005_date\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_01_date\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_015_date\", DoubleType(), True)\\\n",
    " ,StructField(\"balon_date\", DoubleType(), True)\\\n",
    " ,StructField(\"days_after_balon\", IntegerType(), True)\\\n",
    " ,StructField(\"days_balon_starts\", StringType(), True)\\\n",
    " ,StructField(\"balon_sum\", DoubleType(), True)\\\n",
    " ,StructField(\"days_over_lim\", DoubleType(), True)\\\n",
    " ,StructField(\"graph_x\", DoubleType(), True)\\\n",
    " ,StructField(\"graph_y\", DoubleType(), True)\\\n",
    " ,StructField(\"bias\", DoubleType(), True)\\\n",
    " ,StructField(\"gamma\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_005_cumsum_t\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_01_cumsum_t\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_015_cumsum_t\", DoubleType(), True)\\\n",
    " ,StructField(\"balon_sum_t\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_005_cumsum_d\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_01_cumsum_d\", DoubleType(), True)\\\n",
    " ,StructField(\"alpha_015_cumsum_d\", DoubleType(), True)\\\n",
    " ,StructField(\"balon_sum_d\", DoubleType())\\\n",
    " ,StructField(\"nkl_flag\", IntegerType(), True)\\\n",
    " ,StructField(\"vkl_flag\", IntegerType(), True)\\\n",
    " ,StructField(\"num_cr_desc\", IntegerType(), True)\\\n",
    " ])\n",
    "agg_S =agg2[['index','client_id','client_name','inn','kpp','crm_segment','ndog','ddog','dur_in_days','dur_in_month','c_date_ending','date_close','summa_base','summa_ru','c_ft_credit','limit_amt','regime_prod','cred_flag','over_flag','instrument','avp_in_days','avp_in_month','target_cred','product_status','c_list_pay','pr_cred_id','branch','branch_ru','int_revenue','fok_revenue','report_month_ago','c_summa','c_summa_in_cr_v','start_date','end_date','count','wo_summa','wo_summa_in_cr_v','alpha_005_id','alpha_01_id','alpha_015_id','total','alpha_005_cumsum','alpha_01_cumsum','alpha_015_cumsum','alpha_005_date','alpha_01_date','alpha_015_date','balon_date','days_after_balon','days_balon_starts','balon_sum','days_over_lim','graph_x','graph_y','bias','gamma','alpha_005_cumsum_t','alpha_01_cumsum_t','alpha_015_cumsum_t','balon_sum_t','alpha_005_cumsum_d','alpha_01_cumsum_d','alpha_015_cumsum_d','balon_sum_d','nkl_flag','vkl_flag','num_cr_desc']]\n",
    "sqlc.createDataFrame(agg_S, schema=mySchema).write.format(\"parquet\").mode('overwrite').saveAsTable(\"t_team_k7m_aux_p.set_bo_agg\") \n",
    "print('step {}' .format(datetime.datetime.fromtimestamp(time.time()).isoformat()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.3 (ZNO20008661)",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
